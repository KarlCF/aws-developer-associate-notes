## **AWS Monitoring & Audit: CloudWatch, X-Ray and CloudTrail**

### Monitoring in AWS

* AWS CloudWatch:
  * Metrics: Collect and track key metrics
  * Logs: Collect, monitor, analyze and store log files
  * Events: Send notifications when certain events happen in your AWS
  * Alarms: React in real-time to metrics / events
* AWS X-Ray:
  * Troubleshooting application performance and errors
  * Distributed tracing of microservices
* AWS CloudTrail:
  * Internal monitoring of API calls being made
  * Audit changes to AWS Resources by your users

### AWS CloudWatch Metrics

* CloudWatch provides metrics for every services in AWS
* **Metric** is a variable to monitor (CPUUtilization, NetworkIn...)
* Metrics belongs to namespaces
* **Dimension** is an attribute of a metric (instance id, environment, etc...)
* Up to 10 dimensions per metric
* Metrics have **timestamps**
* AWS CloudWatch EC2 Detailed monitoring
  * EC2 instances metrics are by default updated every 5 minutes, detailed monitoring decreases it to 1 minute, but costs more
  * Use detailed monitoring if you want to more promptly scale your ASG
  * EC2 Memory usage is not a default metric, but a custom one.
* AWS CloudWatch Custom Metrics
  * Possibility to define and send your own custom metrics to CloudWatch
  * Ability to use dimnensions (attributes) to segment metrics
    * Instance.id
    * Environment.name
  * Metric Resolution:
    * Standard: 1 minute
    * High Resolution: up to 1 second (**StorageResolution** API parameter) - Higher cost
  * Use API call **PutMetricData**
  * Use exponential back off in case of throttle errors

### AWS CloudWatch Alarms

* Alarms are used to trigger notifications for any metric
* Alarms can go to Auto Scaling, EC2 Actions, SNS notifications
* Various options (sampling, %, max, min, etc...)
* Alarm States:
  * OK
  * INSUFFICIENT_DATA
  * ALARM
* Period:
  * Lenght of time in seconds to evaluate the metric
  * High resolution custom metrics can only choose 10 or 30 sec

### CloudWatch Logs

* Applications can send logs to CloudWatch using the SDK
* CloudWatch can collect log from:
  * ElasticBeanstalk: collection of logs from application
  * ECS: collection from containers
  * AWS Lambda: collection from function logs
  * VPC Flow Logs: VPC specific logs
  * API Gateway
  * CloudTrail based on filter
  * CloudWatch log agents: for example on EC2 machines or on premises
  * Route53: Log DNS queries
* CloudWatch Logs can go to:
  * Batch exporter to S3 for archival
  * Stream to ElasticSearch cluster for further analytics
* CloudWatch Logs can use filter expressions
* Logs storage architecture:
  * Log groups: arbitrary name, usually representing an application
  * Log stream: instances within application / log files / containers
* Can define log expiration policies (never expire, 30 days, etc...)
* Using the AWS CLI we can tail CloudWatch logs
* To send logs to CloudWatch, make sure IAM permissions are correct!
* Security: encryption of logs using KMS are at the Group Level

### CloudWatch Agent & CloudWatch Logs Agent

* By default, no logs from your EC2 machine will go to CloudWatch
* You need to run a CloudWatch agent on EC2 to push the log files 
* Make sure the IAM permissions are satisfied
* The CloudWatch agent can be setup on-premises

#### CloudWatch Logs Agent & Unified Agent

* **CloudWatch Logs Agent**
  * Old version of the agent
  * Can only send to CloudWatch Logs
* **CloudWatch Unified Agent**
  * Collect additional system-level metrics such as RAM, processes, etc...
  * Collect logs to send to CloudWatch Logs
  * Centralized configuration using SSM Parameter Store

### CloudWatch Logs - Encryption

* You can encrypt CloudWatch logs with KMS keys
* Encryption is enabled at the log group level, by associating a CMK with a log group, either when you create the log group or after it exists.
* You cannot associate a CMK with a log group using the CloudWatch console
* You must use the CloudWatch Logs API
  * **associate-kms-key**: if the log group already exists
  * **create-log-group**: if the log group doesn't exist yet
* 

### CloudWatch Logs Metric FIlter 

* CloudWatch Logs can be used to filter expressions
  * For example, find a specific IP inside a log, or count ocurrences of "ERROR" in your logs
  * Metric Filters can be used to trigger alarms
* Filters do not retroactively filter data. Filters only publish the metric data points for events that happen after the filter was created.

### AWS CloudWatch Events

* Schedule: Cron jobs
* Event Pattern: Event rules to react to a service doing something
* Triggers to Lambda functions, SQS / SNS / Kinesis Messages
* CloudWatch Event creates a small JSON document to give information about the change

### EventBridge

* EventBridge is the next evolution of CloudWatch Events
* **Default event bus**: generated by AWS services (CloudWatch Events)
* **Partner event bus**: receive events from SaaS service or applications (Zendesk, DataDog, Segment, Auth0, etc...)
* **Custom event buses**: for your own applications
* Event buses can be accessed by other AWS accounts
* Rules: how to process the events (similar to CloudWatch Events)

#### Amazon EventBridge Schema Registry

* EventBridge can analyze the events in your bus and infer the schema
* The **Schema Registry** allows you to generate code for your application that will know in advance how data is structured in the event bus
* Schema can be versioned

#### Amazon EventBridge vs CloudWatch Events

* Amazon EventBridge builds upon an extends CloudWatch Events
* It uses the same service API and endpoint, and the same underlying service infrastructure
* EventBridge allows extension to add event buses for your custom applications and your third-party SaaS apps.
* EventBridge has the Schema Registry capability
* EventBridge has a different name to mark the new capabilities, and over time, CloudWatch Events will be replaced with EventBridge. 

### AWS X-Ray

* AWS X-Ray provides visual analysis of our applications
* AWS X-Ray advantages:
  * Troubleshooting performance (bottlenecks)
  * Understand dependencies in a microservice architecture
  * Pinpoint service issues
  * Review request behavior
  * Find errors and exceptions
  * Are we meeting time SLA
  * Where I am throttled?
  * Identify users that are impacted
* X-Ray compatibility
  * AWS Lambda
  * Elastic Beanstalk
  * ECS
  * ELB
  * API Gateway
  * EC2 instances or any application servers (even on premises)
* AWS X-Ray Leverages Tracing
  * Tracing is an end to end way to following a "request"
  * Each component dealing with the request adds its own "trace"
  * Tracing is made of segments (+sub segments)
  * Annotations can be added to traces to provide extra-information
  * Ability to trace:
    * Every request
    * Sample request (as a Â¢ for example or a rate per minute)
  * X-Ray Security:
    * IAM for authorization
    * KMS for encryption at rest
* How to enable X-Ray:
  * Your code (Java, Python, Go, Node.js, .NET) must import the AWS X-Ray SDK
  * The application SDK will thencapture:
    * Calls to AWS services
    * HTTP / HTTPS requests
    * Database Calls (MySQL, PostgreSQL, DynamoDB)
    * Queue calls (SQS)
  * Install the X-Ray daemon or enable X-Ray AWS Integration
    * X-Ray daemon works as a low level UDP packet interceptor
    * AWS Lambda / Each application must have the IAM rights to write data to X-Ray
  * To enable on AWS Lambda:
    * Ensure it has an IAM execution role with proper policy (AWSX-RayWriteOnlyAccess)
    * Ensure that X-Ray is imported in the code

### X-Ray Instrumentation in code

* **Instrumentation** means the measure of product's performance, diagnose errors, and to write trace information
* To instrument your application code, you use the X-Ray SDK
* Many SDK require only configuration changes
* You can modify your application code to customize and annotation the data that the SDK sends to X-Ray, using interceptors, filters, handlers, middleware, etc...

### X-Ray Exam tips

* The X-Ray daemon / agent has a config to send traces cross account. This allows to have a central account for all your application tracing:
  * Make sure that the IAM permissions are correct -  the agent will assume the role.
* **Segments**: each application / service will send them
* **Trace**: segments collected together to form an end-to-end trace
* **Sampling**: decrease the amount of requests sent to X-Ray, reduce costs
* **Annotations**: Key Value pairs used to index traces and use with filters
* **Metadata**: Key value pairs, **not indexed**, not used for searching
* Code must be instrumented to use AWS X-Ray SDK (interceptors, handlers, http clients)
* IAM role must be correct to send traces to X-Ray
* **X-Ray on EC2 / on Premises**:
  * Linux system must run the X-Ray daemon
  * IAM instance role if EC2, other AWS credentials on on-premise instance
* **X-Ray on Lambda**:
  * Make sure X-Ray integration is checked on Lambda
* **X-Ray on Beanstalk**:
  * Set configuration on EB console
  * Or use a beanstalk extension (.ebsextensions/xray-daemon.config)
* **X-Ray on ECS / EKS / Fargate (Docker)**:
  * Create a Docker image that runs the Daemon / or use the official X-Ray Docker image
  * Ensure port mappings & network settings are correct and IAM task roles are defined

### X-Ray Sampling Rules

* With sampling rules, you control the amount of data you record
* You can modify sampling rules without changing your code
* By default, the X-Ray SDK records the first request **each second**, and **five percent** of any additional requests
  * One request per second is the reservoir, which ensures that at least one trace is recorded each second as long as the service is serving requests.
  * Five percent is the rate at which additional requests beyond the reservoir size are sampled
* **X-Ray Custom Sampling Rules**
  *  You can create your own rules with the reservoir and rate

### X-Ray API

#### Write 

* **PutTraceSegments**: uploads segment documents to AWS X-Ray
* **PutTelemetryRecords**: Used by the AWS X-Ray daemon to upload telemtry.
  * SegmentsReceivedCount, SegmentsRejectedCount, BackendConnectionErrors, etc...
* **GetSamplingRules**: Retrieve all sampling rules (to know what/when to send), same applies to **GetSamplingTargets** & **GetSamplingStatisticSummaries**
* The X-Ray daemon needs to have an IAM policy authorizing the correct API calls to function correctly

#### Read

* **GetServiceGraph**: main graph
* **BatchGetTraces**: Retrieves a list of traces specified by ID. Each trace is a collection of segment documents that originates from a single request
* **GetTraceSummaries**: Retrieve IDs and annotations for traces available for a specified time frame using an optional filter. To get the full traces, pass the trace IDs to BatchGetTraces
* **GetTraceGraph**: Retrieves a service graph for one or more specific traceIDs.

### AWS CloudTrail

* Provides cgovernance, compliance and audit for your AWS Account
* CloudTrail is enabled by default
* Get an histopy of events / API calls made within your AWS Account by
  * Console
  * SDK
  * CLI
  * AWS Services
* Can put logs from CloudTrail into CloudWatch Logs
* If a resource is deleted in AWS, check CloudTrail

### CloudTrail vs CloudWatch vs X-Ray

* CloudTrail
  * Audit API calls made by users / services / AWS console
  * Useful to detect unauthorized calls or root cause of changes
* CloudWatch:
  * CloudWatch Metrics over time for monitoring
  * CloudWatch Logs for storing application log
  * CloudWatch Alarms to send notifications in case of unexpected metrics
* X-Ray:
  * Automated Trace Analysis & Central Service Map Visualization
  * Latency, Errors and Fault analysis
  * Request tracking accross distributed systems
